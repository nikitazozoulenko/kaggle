{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bcabfd7",
   "metadata": {},
   "source": [
    "Feature selection via SHAP, it like lgbm, xgb importance value. You can train some model then select columns that in top ft importance on almost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    project_dir = Path(os.getcwd())\n",
    "    logs_dir = project_dir / \"logs\"\n",
    "    results_dir = project_dir / \"results\"\n",
    "    data_dir = Path(\"/home/nikita/Data/drw-crypto-market-prediction\") if \"rds\" not in project_dir.as_posix() else project_dir / \"Data/drw-crypto-market-prediction\"\n",
    "    seed = 42\n",
    "    \n",
    "    FEATURES = [\n",
    "        \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
    "        \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
    "        \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\", \"X888\", \"X421\", \"X333\"\n",
    "    ]\n",
    "    TARGET = \"label\"\n",
    "    \n",
    "print(Config.project_dir)\n",
    "print(Config.logs_dir)\n",
    "print(Config.results_dir)\n",
    "print(Config.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#set pandas display options\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "# Set numpy print options\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0c1aa",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ab6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = reduce_mem_usage(pd.read_parquet(Config.data_dir / \"train.parquet\"), \"train\")\n",
    "# test = reduce_mem_usage(pd.read_parquet(Config.data_dir / \"test.parquet\"), \"test\")\n",
    "# sample = pd.read_csv(Config.data_dir / \"sample_submission.csv\")\n",
    "\n",
    "train_X = pd.read_parquet(Config.data_dir / \"train.parquet\",\n",
    "                         #columns=Config.FEATURES + [Config.TARGET]\n",
    "                         ).astype(np.float32)\n",
    "train_y = train_X.pop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766764fa",
   "metadata": {},
   "source": [
    "# Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e461559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant features\n",
    "constant_cols = [col for col in train_X.columns if train_X[col].nunique() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.drop(columns=constant_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f5bdf",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    bid = df['bid_qty']\n",
    "    ask = df['ask_qty']\n",
    "    vol = df['volume']\n",
    "    log1p_vol = np.log1p(vol)\n",
    "    buy = df['buy_qty']\n",
    "    sell = df['sell_qty']\n",
    "    EPS = 1e-6\n",
    "    \n",
    "    # basic features\n",
    "    df['volume_weighted_sell'] = sell * log1p_vol\n",
    "    df['volume_weighted_buy'] = buy * log1p_vol\n",
    "    df['buy_sell_ratio'] = buy / (sell + EPS)\n",
    "    df['selling_pressure'] = sell / (vol + EPS)\n",
    "    \n",
    "    # more advanced features\n",
    "    df['effective_spread_proxy'] = np.abs(buy - sell) / (vol + EPS)\n",
    "    df['order_imbalance'] = (bid - ask) / (bid + ask + EPS)\n",
    "    df['flow_imbalance'] = (buy - sell) / (buy + sell + EPS)\n",
    "    df['liquidity_ratio'] = (bid + ask) / (vol + EPS)\n",
    "    \n",
    "    # some more advanced features from kaggle\n",
    "    df['kyle_lambda'] = df['flow_imbalance'] * np.sqrt(df['order_imbalance'].abs()) / (log1p_vol + EPS)\n",
    "    df['vol_adjusted_pressure'] =  np.log1p(bid + ask) * np.exp(-vol / (vol.mean() + EPS))\n",
    "    buy_intensity = buy / (vol + 1e-6)\n",
    "    sell_intensity = sell / (vol + 1e-6)\n",
    "    df['trade_intensity_asymmetry'] = np.sign(buy_intensity - sell_intensity) * \\\n",
    "                            np.log1p(np.abs(buy_intensity - sell_intensity))\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "add_features(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe15d0",
   "metadata": {},
   "source": [
    "# Pairwise correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df and the target column is 'target'\n",
    "# Drop the target column to focus only on features\n",
    "feature_df = train_X.drop(columns=['label'], errors='ignore')\n",
    "\n",
    "# Compute pairwise Pearson correlation matrix\n",
    "correlation_matrix = feature_df.corr(method='pearson')\n",
    "\n",
    "# Display shape and sample\n",
    "print(\"Correlation matrix shape:\", correlation_matrix.shape)\n",
    "correlation_matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39099d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask upper triangle to avoid duplicate pairs and self-correlation\n",
    "mask = np.triu(np.ones(correlation_matrix.shape), k=1)\n",
    "corr_matrix_masked = correlation_matrix.where(mask == 1)\n",
    "\n",
    "corr_pairs = corr_matrix_masked[\n",
    "    (0.98 < corr_matrix_masked.abs())# & (corr_matrix_masked.abs() < 1)\n",
    "].stack().reset_index()\n",
    "corr_pairs.columns = ['feature_1', 'feature_2', 'correlation']\n",
    "corr_pairs = corr_pairs.sort_values(by='correlation', ascending=False)\n",
    "\n",
    "# Show result\n",
    "print(f\"Found {len(corr_pairs)} feature pairs.\")\n",
    "corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad204bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {}\n",
    "used = set()\n",
    "for v1, v2 in zip(corr_pairs['feature_1'], corr_pairs['feature_2']):\n",
    "    if v2 not in used:\n",
    "        if v1 not in pairs:\n",
    "            pairs[v1] = [v1, v2]\n",
    "            used.add(v1)\n",
    "            used.add(v2)\n",
    "        elif v2 not in pairs[v1]:\n",
    "            pairs[v1] += [v2]\n",
    "            used.add(v2)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copies_to_drop = []\n",
    "for k, v in pairs.items():\n",
    "    copies_to_drop += v[1:]\n",
    "print(f\"Number of features to drop: {len(copies_to_drop)}\")\n",
    "print(\"['\" + \"', '\".join(sorted(copies_to_drop)) + \"']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop0999 = ['X146', 'X104', 'X116', 'X158', 'X110', 'X152', 'X122', 'X164', 'X170', 'X128', 'X134', 'X176', 'X140', 'X182', 'X363', 'X399', 'X357', 'X393', 'X351', 'X405', 'X411', 'X417', 'X423', 'X429', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294']\n",
    "drop0995 = ['X417', 'X423', 'X429', 'X104', 'X146', 'X110', 'X152', 'X393', 'X399', 'X405', 'X411', 'X116', 'X158', 'X122', 'X164', 'X128', 'X170', 'X134', 'X176', 'X140', 'X182', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294', 'X295', 'X634', 'X302', 'X48', 'X47', 'X303', 'X55', 'X288', 'X56', 'X289', 'X489', 'X619', 'X490', 'X488', 'X296', 'X42', 'X491', 'X41', 'X297', 'X622', 'X494', 'X492', 'X493', 'X242', 'X50', 'X49', 'X243', 'X283', 'X241', 'X282', 'X244', 'X290', 'X245', 'X246']\n",
    "drop099 = ['X393', 'X429', 'X423', 'X417', 'X411', 'X405', 'X399', 'X110', 'X152', 'X116', 'X158', 'X122', 'X164', 'X104', 'X146', 'X128', 'X170', 'X182', 'X140', 'X176', 'X134', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294', 'X295', 'X634', 'X302', 'X48', 'X47', 'X303', 'X55', 'X288', 'X56', 'X289', 'X489', 'X619', 'X490', 'X488', 'X296', 'X42', 'X491', 'X41', 'X297', 'X622', 'X494', 'X492', 'X493', 'X242', 'X50', 'X49', 'X243', 'X283', 'X241', 'X282', 'X244', 'X290', 'X245', 'X246', 'X8', 'X291', 'X247', 'X886', 'X36', 'X191', 'X44', 'X696', 'X43', 'X435', 'X35', 'X887', 'X255']\n",
    "drop098 = ['X104', 'X110', 'X116', 'X122', 'X128', 'X134', 'X140', 'X146', 'X152', 'X158', 'X16', 'X164', 'X170', 'X176', 'X182', 'X191', 'X241', 'X242', 'X243', 'X244', 'X245', 'X246', 'X247', 'X255', 'X263', 'X282', 'X283', 'X284', 'X285', 'X288', 'X289', 'X290', 'X291', 'X294', 'X295', 'X296', 'X297', 'X300', 'X301', 'X302', 'X303', 'X35', 'X351', 'X357', 'X36', 'X363', 'X369', 'X375', 'X38', 'X381', 'X387', 'X393', 'X399', 'X405', 'X41', 'X411', 'X417', 'X42', 'X423', 'X429', 'X43', 'X434', 'X435', 'X438', 'X44', 'X47', 'X48', 'X488', 'X489', 'X49', 'X490', 'X491', 'X492', 'X493', 'X494', 'X50', 'X53', 'X54', 'X55', 'X56', 'X619', 'X622', 'X631', 'X634', 'X643', 'X646', 'X655', 'X658', 'X667', 'X669', 'X670', 'X672', 'X679', 'X681', 'X682', 'X684', 'X691', 'X694', 'X696', 'X789', 'X793', 'X797', 'X8', 'X801', 'X805', 'X817', 'X821', 'X825', 'X886', 'X887']\n",
    "drop095 = ['X399', 'X357', 'X393', 'X351', 'X411', 'X369', 'X405', 'X363', 'X417', 'X375', 'X429', 'X387', 'X110', 'X152', 'X164', 'X122', 'X182', 'X176', 'X339', 'X423', 'X158', 'X116', 'X170', 'X104', 'X146', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294', 'X295', 'X634', 'X302', 'X48', 'X47', 'X303', 'X55', 'X288', 'X56', 'X289', 'X489', 'X619', 'X490', 'X488', 'X296', 'X42', 'X491', 'X41', 'X297', 'X622', 'X494', 'X492', 'X493', 'X242', 'X50', 'X49', 'X243', 'X283', 'X241', 'X282', 'X244', 'X290', 'X245', 'X246', 'X8', 'X291', 'X247', 'X886', 'X36', 'X191', 'X44', 'X696', 'X43', 'X435', 'X35', 'X887', 'X255', 'X438', 'X16', 'X285', 'X284', 'X684', 'X434', 'X789', 'X263', 'X793', 'X672', 'X797', 'X817', 'X821', 'X801', 'X38', 'X669', 'X825', 'X805', 'X681', 'X450', 'X753', 'X737', 'X749', 'X741', 'X809', 'X745', 'X449', 'X451', 'X37', 'X733', 'X829', 'X624', 'X453', 'X757', 'X5', 'X452', 'X660', 'X448', 'X719', 'X813', 'X721', 'X723', 'X447', 'X454', 'X205', 'X433', 'X725', 'X204', 'X693', 'X833', 'X455', 'X252', 'X459', 'X203', 'X657', 'X456', 'X837', 'X206', 'X727', 'X207', 'X437', 'X404', 'X841', 'X208', 'X132', 'X457', 'X889', 'X202', 'X209', 'X874', 'X138', 'X180', 'X187', 'X210', 'X410', 'X729', 'X93', 'X13', 'X211', 'X120', 'X385', 'X879', 'X337', 'X6', 'X90', 'X765', 'X761', 'X271', 'X78', 'X343', 'X24', 'X427', 'X769', 'X362', 'X260', 'X325', 'X190', 'X880', 'X212', 'X157', 'X621', 'X368', 'X773', 'X422', 'X605', 'X692', 'X341', 'X96', 'X162', 'X731', 'X428', 'X32', 'X340', 'X367', 'X326', 'X868', 'X409', 'X163', 'X466', 'volume', 'X338', 'X383', 'X425', 'X380', 'X186', 'X344', 'X785', 'X473', 'X75', 'X386', 'X777', 'X135', 'X253', 'X612', 'X842', 'X814', 'X781', 'X882', 'X865', 'X480', 'X786']\n",
    "drop09 = ['X128', 'X170', 'X333', 'X122', 'X164', 'X327', 'X158', 'X116', 'X387', 'X429', 'X393', 'X140', 'X176', 'X134', 'X381', 'X423', 'X405', 'X399', 'X411', 'X152', 'X315', 'X146', 'X182', 'X417', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294', 'X295', 'X634', 'X302', 'X48', 'X47', 'X303', 'X55', 'X288', 'X56', 'X289', 'X489', 'X619', 'X490', 'X488', 'X296', 'X42', 'X491', 'X41', 'X297', 'X622', 'X494', 'X492', 'X493', 'X242', 'X50', 'X49', 'X243', 'X283', 'X241', 'X282', 'X244', 'X290', 'X245', 'X246', 'X8', 'X291', 'X247', 'X886', 'X36', 'X191', 'X44', 'X696', 'X43', 'X435', 'X35', 'X887', 'X255', 'X438', 'X16', 'X285', 'X284', 'X684', 'X434', 'X789', 'X263', 'X793', 'X672', 'X797', 'X817', 'X821', 'X801', 'X38', 'X669', 'X825', 'X805', 'X681', 'X450', 'X753', 'X737', 'X749', 'X741', 'X809', 'X745', 'X449', 'X451', 'X37', 'X733', 'X829', 'X624', 'X453', 'X757', 'X5', 'X452', 'X660', 'X448', 'X719', 'X813', 'X721', 'X723', 'X447', 'X468', 'X454', 'X205', 'X433', 'X725', 'X204', 'X693', 'X833', 'X455', 'X252', 'X459', 'X203', 'X657', 'X456', 'X837', 'X206', 'X727', 'X207', 'X437', 'X404', 'X841', 'X208', 'X132', 'X457', 'X889', 'X202', 'X209', 'X874', 'X138', 'X180', 'X187', 'X210', 'X410', 'X729', 'X93', 'X13', 'X211', 'X120', 'X321', 'X385', 'X879', 'X337', 'X6', 'X90', 'X765', 'X761', 'X271', 'X78', 'X343', 'X24', 'X427', 'X769', 'X362', 'X260', 'X325', 'X190', 'X880', 'X212', 'X157', 'X621', 'X368', 'X773', 'X422', 'X605', 'X692', 'X341', 'X96', 'X162', 'X731', 'X428', 'X32', 'X340', 'X367', 'X326', 'X309', 'X868', 'X409', 'X163', 'X466', 'volume', 'X338', 'X383', 'X425', 'X380', 'X186', 'X344', 'X785', 'X473', 'X75', 'X386', 'X777', 'X135', 'X253', 'X612', 'X842', 'X814', 'X781', 'X882', 'X865', 'X480', 'X786', 'X758', 'X115', 'X113', 'X71', 'X279', 'X21', 'X219', 'X322', 'X155', 'X268', 'X360', 'X177', 'X28', 'X318', 'X426', 'X119', 'X883', 'X275', 'X29', 'X467', 'X602', 'X161', 'X890', 'X695', 'X77', 'X121', 'X402', 'X173', 'X366', 'X378', 'X382', 'X324', 'X276', 'X358', 'X408', 'X323', 'X175', 'X407', 'X117', 'X179', 'X689', 'X131', 'X384', 'X400', 'X364', 'X436', 'X609', 'X153', 'X365', 'X159', 'X406', 'X462', 'X474', 'X336', 'X424', 'X463', 'X137', 'X342', 'X181', 'X746', 'X89', 'X774', 'X830', 'X194', 'X73', 'X130', 'X166', 'X95', 'X136', 'X178', 'X88', 'X79', 'X802', 'X76', 'X97', 'X160', 'X118', 'X94', 'X133', 'X139', 'X216', 'X227', 'X226', 'X232', 'X220', 'X680', 'X14', 'X653', 'X470', 'X477', 'X250', 'X261', 'X3', 'X471', 'X668', 'X233', 'X223', 'X475', 'X168', 'X518', 'X373', 'X650', 'X415', 'X861', 'X596', 'X854']\n",
    "drop05 = ['X158', 'X417', 'X164', 'X357', 'X399', 'X393', 'X351', 'X134', 'X176', 'X339', 'X98', 'X411', 'X170', 'X429', 'X146', 'X423', 'X152', 'X405', 'X363', 'X182', 'X345', 'X694', 'X691', 'X682', 'X679', 'X670', 'X667', 'X655', 'X300', 'X658', 'X301', 'X53', 'X643', 'X54', 'X646', 'X631', 'X294', 'X295', 'X634', 'X302', 'X48', 'X47', 'X303', 'X55', 'X288', 'X56', 'X289', 'X489', 'X619', 'X490', 'X488', 'X296', 'X42', 'X491', 'X41', 'X297', 'X622', 'X494', 'X492', 'X493', 'X242', 'X50', 'X49', 'X243', 'X283', 'X241', 'X282', 'X244', 'X290', 'X245', 'X246', 'X8', 'X291', 'X247', 'X886', 'X36', 'X191', 'X44', 'X696', 'X43', 'X435', 'X35', 'X185', 'X887', 'X255', 'X438', 'X16', 'X285', 'X284', 'X684', 'X434', 'X789', 'X263', 'X793', 'X672', 'X797', 'X817', 'X821', 'X801', 'X38', 'X669', 'X825', 'X805', 'X681', 'X450', 'X753', 'X737', 'X749', 'X741', 'X809', 'X745', 'X449', 'X451', 'X37', 'X733', 'X829', 'X624', 'X453', 'X757', 'X5', 'X452', 'X660', 'X448', 'X719', 'X813', 'X721', 'X723', 'X447', 'X468', 'X454', 'X205', 'X433', 'X725', 'X204', 'X693', 'X833', 'X455', 'X252', 'X459', 'X203', 'X657', 'X456', 'X837', 'X206', 'X727', 'X207', 'X437', 'X404', 'X841', 'X208', 'X132', 'X457', 'X889', 'X202', 'X209', 'X874', 'X138', 'X180', 'X187', 'X333', 'X210', 'X410', 'X729', 'X93', 'X327', 'X13', 'X211', 'X120', 'X385', 'X879', 'X337', 'X6', 'X90', 'X765', 'X761', 'X271', 'X78', 'X343', 'X24', 'X427', 'X769', 'X362', 'X392', 'X260', 'X325', 'X190', 'X880', 'X212', 'X157', 'X621', 'X368', 'X773', 'X422', 'X605', 'X692', 'X341', 'X96', 'X162', 'X731', 'X428', 'X32', 'X857', 'X340', 'X367', 'X326', 'X868', 'X272', 'X409', 'X163', 'X466', 'volume', 'X338', 'X383', 'X425', 'X380', 'X186', 'X344', 'X785', 'X473', 'X75', 'X386', 'X777', 'X135', 'X253', 'X612', 'X842', 'X814', 'X781', 'X882', 'X865', 'X25', 'X480', 'X786', 'X758', 'X115', 'X145', 'X113', 'X71', 'X279', 'X21', 'X219', 'X322', 'X155', 'X268', 'X360', 'X177', 'X28', 'X318', 'X426', 'X119', 'X883', 'X275', 'X29', 'X467', 'X460', 'X602', 'X161', 'X890', 'X695', 'X77', 'X121', 'X402', 'X173', 'X366', 'X378', 'X382', 'X324', 'X276', 'X358', 'X408', 'X323', 'X175', 'X407', 'X117', 'X179', 'X689', 'X131', 'X384', 'X400', 'X364', 'X436', 'X609', 'X153', 'X365', 'X159', 'X406', 'X462', 'X474', 'X336', 'X424', 'X463', 'X137', 'X342', 'X181', 'X861', 'X746', 'X89', 'X774', 'X830', 'X194', 'X73', 'X103', 'X130', 'X166', 'X95', 'X136', 'X178', 'X88', 'X79', 'X802', 'X74', 'X76', 'X97', 'X160', 'X118', 'X94', 'X133', 'X80', 'X139', 'X216', 'X227', 'X226', 'X232', 'X220', 'X680', 'X14', 'X653', 'X470', 'X477', 'X250', 'X261', 'X3', 'X471', 'X668', 'X233', 'X223', 'X475', 'X168', 'X518', 'X373', 'X650', 'X644', 'X415', 'X11', 'X594', 'X148', 'X258', 'X224', 'X516', 'X142', 'X81', 'X314', 'X350', 'X530', 'X371', 'X532', 'X567', 'X565', 'X581', 'X413', 'X108', 'X269', 'X230', 'X328', 'X22', 'X858', 'X266', 'X346', 'X273', 'X63', 'X313', 'X603', 'X19', 'X26', 'X397', 'X579', 'X30', 'X189', 'X588', 'X310', 'X150', 'X228', 'X539', 'X355', 'X66', 'X123', 'X517', 'X610', 'X600', 'X414', 'X778', 'X656', 'X607', 'X586', 'X277', 'X659', 'X834', 'X750', 'X370', 'X105', 'X141', 'X165', 'X412', 'X806', 'X636', 'X642', 'X85', 'X395', 'X214', 'X537', 'X353', 'X311', 'X766', 'X86', 'X64', 'X822', 'X738', 'X735', 'X671', 'X794', 'X791', 'X531', 'X665', 'X629', 'X623', 'X478', 'X566', 'X580', 'X639', 'X633', 'X859', 'X597', 'X587', 'X538', 'X501', 'X533', 'X528', 'X540', 'X508', 'X515', 'X519', 'X514', 'X522', 'X851', 'X849', 'X850', 'X542', 'X866', 'X743', 'X755', 'X759', 'X831', 'X504', 'X775', 'X747', 'X632', 'X569', 'X564', 'X839', 'X783', 'X648', 'X557', 'X521', 'X845', 'X843', 'X502', 'X582', 'X550', 'X787', 'X529', 'X534', 'X799', 'X143', 'X846', 'X847', 'X571', 'X803', 'X553', 'X551', 'X256', 'X589', 'X578', 'X583', 'X536', 'X543', 'X811', 'X568', 'X503', 'X552', 'X815', 'X585', 'X877', 'X9', 'X584', 'X590', 'X620', 'X507', 'X592', 'X591', 'X570', 'X635', 'X500', 'X860', 'X348', 'X823', 'X767', 'X862', 'X856', 'X390', 'X556', 'X549', 'X593', 'X388', 'X876', 'X596', 'X854']\n",
    "\n",
    "print(\"drop0999 len:\", len(drop0999))\n",
    "print(\"drop0995 len:\", len(drop0995))\n",
    "print(\"drop099 len:\", len(drop099))\n",
    "print(\"drop095 len:\", len(drop095))\n",
    "print(\"drop09 len:\", len(drop09))\n",
    "print(\"drop05 len:\", len(drop05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfc9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check how much cv score lin reg decreases with each drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b81d5",
   "metadata": {},
   "source": [
    "# Final features to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_corr_drop = ['X39', 'X41', 'X40', 'X42', 'X45', 'X47', 'X46', 'X48', 'X47', \n",
    "#                   'X49', 'X48', 'X50', 'X51', 'X53', 'X55', 'X52', 'X54', 'X56', \n",
    "#                   'X62', 'X104', 'X146', 'X68', 'X110', 'X152', 'X74', 'X116', \n",
    "#                   'X158', 'X80', 'X122', 'X164', 'X86', 'X128', 'X170', 'X92', \n",
    "#                   'X134', 'X176', 'X98', 'X140', 'X182', 'X234', 'X241', 'X235', \n",
    "#                   'X242', 'X236', 'X243', 'X237', 'X244', 'X238', 'X245', 'X239', \n",
    "#                   'X246', 'X280', 'X282', 'X281', 'X283', 'X286', 'X288', 'X287', \n",
    "#                   'X289', 'X288', 'X290', 'X292', 'X294', 'X293', 'X295', 'X294', \n",
    "#                   'X296', 'X295', 'X297', 'X298', 'X300', 'X302', 'X299', 'X301', \n",
    "#                   'X303', 'X309', 'X351', 'X393', 'X315', 'X357', 'X399', 'X321', \n",
    "#                   'X363', 'X405', 'X327', 'X369', 'X411', 'X333', 'X375', 'X417', \n",
    "#                   'X339', 'X381', 'X423', 'X345', 'X387', 'X429', 'X481', 'X488', \n",
    "#                   'X482', 'X489', 'X483', 'X490', 'X484', 'X491', 'X485', 'X492', \n",
    "#                   'X486', 'X493', 'X487', 'X494', 'X613', 'X619', 'X616', 'X622', \n",
    "#                   'X625', 'X631', 'X628', 'X634', 'X637', 'X643', 'X640', 'X646', \n",
    "#                   'X649', 'X655', 'X652', 'X658', 'X661', 'X667', 'X664', 'X670', \n",
    "#                   'X673', 'X679', 'X676', 'X682', 'X685', 'X691', 'X688', 'X694']\n",
    "\n",
    "# constant_cols = ['X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', \n",
    "#                  'X706', 'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', \n",
    "#                  'X715', 'X716', 'X717', 'X864', 'X867', 'X869', 'X870', 'X871', 'X872']\n",
    "\n",
    "# train_X.drop(columns=high_corr_drop + constant_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1fa4a",
   "metadata": {},
   "source": [
    "# cv code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do i want to do here? \n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def xgb_params(trial):\n",
    "    return {\n",
    "        # fixed\n",
    "        'objective': trial.suggest_categorical('objective', ['reg:squarederror']),\n",
    "        'tree_method': trial.suggest_categorical('tree_method', ['hist']),\n",
    "        'device': trial.suggest_categorical('device', ['cuda']),\n",
    "        # 'predictor': trial.suggest_categorical('predictor', ['gpu_predictor']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [Config.seed]),\n",
    "        # hyperparams\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 100, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 0.25, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.3, 0.7),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.3, 0.7),\n",
    "        'lambda': trial.suggest_float('lambda', 10, 200, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 10, 100, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 3.0),\n",
    "    }# other: n_jobs, random_state, verbose, max_leaves, min_child_weight\n",
    "\n",
    "\n",
    "\n",
    "def lgbm_params(trial):\n",
    "    return {\n",
    "        # fixed\n",
    "        'objective': trial.suggest_categorical('objective', ['regression']),\n",
    "        'device': trial.suggest_categorical('device', ['cuda']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [Config.seed]),\n",
    "        'verbose': trial.suggest_categorical('verbose', [0]),  # no output\n",
    "        # hyperparams\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 100, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 128),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 0.25, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.3, 0.7),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 10, 100, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 10, 200, log=True),\n",
    "    }# other? goss\n",
    "\n",
    "\n",
    "def catb_params(trial):\n",
    "    return {\n",
    "        # fixed\n",
    "        # 'loss_function': trial.suggest_categorical('loss_function', ['RMSE']),\n",
    "        'task_type': trial.suggest_categorical('task_type', ['GPU']),\n",
    "        'random_state': trial.suggest_categorical('random_state', [Config.seed]),\n",
    "        'verbose': trial.suggest_categorical('verbose', [0]),  # no output\n",
    "        'leaf_estimation_iterations': trial.suggest_categorical('leaf_estimation_iterations', [5]), #default 10\n",
    "        # hyperparams\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 100, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 0.25, log=True),\n",
    "        #'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.05, 0.25, log=True), # only supported on cpu\n",
    "        #'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bernoulli']),  \n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 10, 200, log=True),\n",
    "    }# other? max_bin?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ive decided to use naive nested 5 fold to do the tuning. \n",
    "# maybe setting one of them to None can yield back simple kfold. \n",
    "# not sure what to do yet for ensembling, but this is an issue for way later\n",
    "\n",
    "import optuna\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "    \n",
    "def do_opuna_optimization(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    ModelClass: BaseEstimator,\n",
    "    params_fn: Callable = xgb_params,\n",
    "    n_trials: int = 100,\n",
    "    cv = KFold(n_splits=5, shuffle=False),\n",
    "):\n",
    "    #Configure logging\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    log_dir = Config.logs_dir / ModelClass.__name__\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO) \n",
    "    logger.addHandler(logging.FileHandler(log_dir / f\"optuna{timestamp}.log\", mode=\"w\"))  # Log to a file named \"optuna.log\"\n",
    "    optuna.logging.enable_propagation()\n",
    "    \n",
    "    #optuna objective\n",
    "    def objective(trial):\n",
    "        params = params_fn(trial)\n",
    "        scores = []\n",
    "        for train_idx, valid_idx in cv.split(X, y):\n",
    "            X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "            y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "            mdl = ModelClass(**params)\n",
    "            mdl.fit(X_train, y_train)\n",
    "            preds = mdl.predict(X_valid)\n",
    "            rho, _ = pearsonr(y_valid, preds)\n",
    "            scores.append(rho)\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", \n",
    "                                sampler=optuna.samplers.TPESampler(seed=Config.seed))\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(\"Best trial:\", study.best_trial.number)\n",
    "    print(\"Best value (CV RMSE):\", study.best_value)\n",
    "    print(\"Best params:\", study.best_params)\n",
    "    return study\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_opuna_optimization(\n",
    "    X=train_X.values,\n",
    "    y=train_y.values,\n",
    "    ModelClass=XGBRegressor,\n",
    "    params_fn=xgb_params,\n",
    "    n_trials=5,\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac599fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_opuna_optimization(\n",
    "    X=train_X.values,\n",
    "    y=train_y.values,\n",
    "    ModelClass=LGBMRegressor,\n",
    "    params_fn=lgbm_params,\n",
    "    n_trials=5,\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_opuna_optimization(\n",
    "    X=train_X.values,\n",
    "    y=train_y.values,\n",
    "    ModelClass=CatBoostRegressor,\n",
    "    params_fn=catb_params,\n",
    "    n_trials=5,\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bed013",
   "metadata": {},
   "source": [
    "# I need to do feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i need to train a single model and do feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbc824",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26538e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/nz423/home/miniforge3/envs/hydraboost/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['volume_weighted_sell'] = sell * log1p_vol\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['volume_weighted_buy'] = buy * log1p_vol\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['buy_sell_ratio'] = buy / (sell + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:154: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['selling_pressure'] = sell / (vol + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['effective_spread_proxy'] = np.abs(buy - sell) / (vol + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['order_imbalance'] = (bid - ask) / (bid + ask + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:159: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['flow_imbalance'] = (buy - sell) / (buy + sell + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:160: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['liquidity_ratio'] = (bid + ask) / (vol + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['kyle_lambda'] = df['flow_imbalance'] * np.sqrt(df['order_imbalance'].abs()) / (log1p_vol + EPS)\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['vol_adjusted_pressure'] =  np.log1p(bid + ask) * np.exp(-vol / (vol.mean() + EPS))\n",
      "/rds/general/user/nz423/home/kaggle/do_optuna.py:167: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['trade_intensity_asymmetry'] = np.sign(buy_intensity - sell_intensity) * \\\n",
      "[I 2025-06-25 21:36:34,747] A new study created in memory with name: no-name-f7eb7958-08de-4317-912b-6f19240a3a17\n",
      "/rds/general/user/nz423/home/miniforge3/envs/hydraboost/lib/python3.11/site-packages/xgboost/core.py:729: UserWarning: [21:38:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x1539d893bf50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/rds/general/user/nz423/home/miniforge3/envs/hydraboost/lib/python3.11/site-packages/xgboost/core.py\", line 585, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "%run kaggle/do_optuna.py \\\n",
    "    --models \"XGBoost\" \\\n",
    "    --logs_dir \"/rds/general/user/nz423/home/kaggle/logs/\" \\\n",
    "    --data_dir \"/rds/general/user/nz423/home/Data/drw-crypto-market-prediction/\" \\\n",
    "    --n_optuna_trials 5 \\\n",
    "    --kfolds 5 \\\n",
    "    --seed 42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.11 (hydraboost)",
   "language": "python",
   "name": "python311_hydraboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
